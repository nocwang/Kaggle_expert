{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43c38433-6d17-4b1e-9f2a-bca4f692489a",
    "_execution_state": "idle",
    "_uuid": "ea7d07e39f8c6160c05767de0c4f7f6489ebe8df"
   },
   "source": [
    "msk-redefining-cancer-treatment\n",
    "\n",
    "Personalized Medicine: Redefining Cancer Treatment | Kaggle\n",
    "============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e99beda1-d7bb-4de3-916c-327d1f2d87e2",
    "_execution_state": "busy",
    "_uuid": "92a8330e090e0074e540f721894351f10a6946d6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yannisplab/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/yannisplab/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/home/yannisplab/anaconda3/lib/python3.6/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/home/yannisplab/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/home/yannisplab/anaconda3/lib/python3.6/site-packages/sklearn/qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import log_loss                                                         \n",
    "from sklearn.ensemble import RandomForestClassifier                                             \n",
    "from sklearn.model_selection import KFold                                                       \n",
    "#from sklearn.metrics import accuracy_score   \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('../input/training_variants')\n",
    "test = pd.read_csv('../input/test_variants')\n",
    "trainx = pd.read_csv('../input/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "testx = pd.read_csv('../input/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, trainx, how='left', on='ID').fillna('')\n",
    "y = train['Class'].values\n",
    "train = train.drop(['Class'], axis=1)\n",
    "\n",
    "test = pd.merge(test, testx, how='left', on='ID').fillna('')\n",
    "pid = test['ID'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if 1st time, uncomment below and comment next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3260\n",
      "3091\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "# df_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "# df_all['Gene_Share'] = df_all.apply(lambda r: sum([1 for w in r['Gene'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "# df_all['Variation_Share'] = df_all.apply(lambda r: sum([1 for w in r['Variation'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "\n",
    "# #commented for Kaggle Limits\n",
    "# for i in range(56):\n",
    "#     df_all['Gene_'+str(i)] = df_all['Gene'].map(lambda x: str(x[i]) if len(x)>i else '')\n",
    "#     df_all['Variation'+str(i)] = df_all['Variation'].map(lambda x: str(x[i]) if len(x)>i else '')\n",
    "\n",
    "\n",
    "# gen_var_lst = sorted(list(train.Gene.unique()) + list(train.Variation.unique()))\n",
    "# print(len(gen_var_lst))\n",
    "# gen_var_lst = [x for x in gen_var_lst if len(x.split(' '))==1]\n",
    "# print(len(gen_var_lst))\n",
    "# i_ = 0\n",
    "# #commented for Kaggle Limits\n",
    "# for gen_var_lst_itm in gen_var_lst:\n",
    "#     if i_ % 100 == 0: print(i_)\n",
    "#     df_all['GV_'+str(gen_var_lst_itm)] = df_all['Text'].map(lambda x: str(x).count(str(gen_var_lst_itm)))\n",
    "#     i_ += 1\n",
    "\n",
    "# for c in df_all.columns:\n",
    "#     if df_all[c].dtype == 'object':\n",
    "#         if c in ['Gene','Variation']:\n",
    "#             lbl = preprocessing.LabelEncoder()\n",
    "#             df_all[c+'_lbl_enc'] = lbl.fit_transform(df_all[c].values)  \n",
    "#             df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "#             df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' ')))\n",
    "#         elif c != 'Text':\n",
    "#             lbl = preprocessing.LabelEncoder()\n",
    "#             df_all[c] = lbl.fit_transform(df_all[c].values)\n",
    "#         if c=='Text': \n",
    "#             df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "#             df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' '))) \n",
    "\n",
    "\n",
    "\n",
    "#df_all.to_csv('df_all.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if 2nd time run, comment above and use below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8989, 3217)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene_Share</th>\n",
       "      <th>Variation_Share</th>\n",
       "      <th>Gene_0</th>\n",
       "      <th>Variation0</th>\n",
       "      <th>Gene_1</th>\n",
       "      <th>Variation1</th>\n",
       "      <th>Gene_2</th>\n",
       "      <th>Variation2</th>\n",
       "      <th>Gene_3</th>\n",
       "      <th>...</th>\n",
       "      <th>GV_YAP1</th>\n",
       "      <th>GV_p61BRAF</th>\n",
       "      <th>Gene_lbl_enc</th>\n",
       "      <th>Gene_len</th>\n",
       "      <th>Gene_words</th>\n",
       "      <th>Variation_lbl_enc</th>\n",
       "      <th>Variation_len</th>\n",
       "      <th>Variation_words</th>\n",
       "      <th>Text_len</th>\n",
       "      <th>Text_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.0</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2399.948604</td>\n",
       "      <td>0.359328</td>\n",
       "      <td>0.815775</td>\n",
       "      <td>9.350873</td>\n",
       "      <td>16.880187</td>\n",
       "      <td>19.078095</td>\n",
       "      <td>6.105796</td>\n",
       "      <td>17.844699</td>\n",
       "      <td>8.071866</td>\n",
       "      <td>12.848036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366448</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>700.801201</td>\n",
       "      <td>4.564913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4271.975971</td>\n",
       "      <td>5.742797</td>\n",
       "      <td>1.036823</td>\n",
       "      <td>59063.762042</td>\n",
       "      <td>8905.540550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1532.553437</td>\n",
       "      <td>0.479830</td>\n",
       "      <td>0.423356</td>\n",
       "      <td>6.876197</td>\n",
       "      <td>6.422781</td>\n",
       "      <td>7.303647</td>\n",
       "      <td>7.438880</td>\n",
       "      <td>7.648407</td>\n",
       "      <td>7.744326</td>\n",
       "      <td>10.791715</td>\n",
       "      <td>...</td>\n",
       "      <td>6.402976</td>\n",
       "      <td>0.460156</td>\n",
       "      <td>432.263522</td>\n",
       "      <td>1.174447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2514.680898</td>\n",
       "      <td>3.070985</td>\n",
       "      <td>0.217404</td>\n",
       "      <td>37051.380894</td>\n",
       "      <td>5597.929867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1123.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2068.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37955.000000</td>\n",
       "      <td>5700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2247.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4259.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53101.000000</td>\n",
       "      <td>8040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3420.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1076.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6484.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70410.000000</td>\n",
       "      <td>10598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5667.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1506.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8608.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>523393.000000</td>\n",
       "      <td>77202.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 3214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID   Gene_Share  Variation_Share       Gene_0   Variation0  \\\n",
       "count  8989.000000  8989.000000      8989.000000  8989.000000  8989.000000   \n",
       "mean   2399.948604     0.359328         0.815775     9.350873    16.880187   \n",
       "std    1532.553437     0.479830         0.423356     6.876197     6.422781   \n",
       "min       0.000000     0.000000         0.000000     0.000000     0.000000   \n",
       "25%    1123.000000     0.000000         1.000000     2.000000    11.000000   \n",
       "50%    2247.000000     0.000000         1.000000    10.000000    17.000000   \n",
       "75%    3420.000000     1.000000         1.000000    15.000000    22.000000   \n",
       "max    5667.000000     1.000000         5.000000    25.000000    31.000000   \n",
       "\n",
       "            Gene_1   Variation1       Gene_2   Variation2       Gene_3  \\\n",
       "count  8989.000000  8989.000000  8989.000000  8989.000000  8989.000000   \n",
       "mean     19.078095     6.105796    17.844699     8.071866    12.848036   \n",
       "std       7.303647     7.438880     7.648407     7.744326    10.791715   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      12.000000     2.000000    12.000000     4.000000     3.000000   \n",
       "50%      20.000000     4.000000    17.000000     7.000000    12.000000   \n",
       "75%      26.000000     7.000000    24.000000     9.000000    24.000000   \n",
       "max      34.000000    44.000000    35.000000    44.000000    37.000000   \n",
       "\n",
       "           ...           GV_YAP1   GV_p61BRAF  Gene_lbl_enc     Gene_len  \\\n",
       "count      ...       8989.000000  8989.000000   8989.000000  8989.000000   \n",
       "mean       ...          0.366448     0.017800    700.801201     4.564913   \n",
       "std        ...          6.402976     0.460156    432.263522     1.174447   \n",
       "min        ...          0.000000     0.000000      0.000000     2.000000   \n",
       "25%        ...          0.000000     0.000000    321.000000     4.000000   \n",
       "50%        ...          0.000000     0.000000    680.000000     4.000000   \n",
       "75%        ...          0.000000     0.000000   1076.000000     5.000000   \n",
       "max        ...        321.000000    22.000000   1506.000000     9.000000   \n",
       "\n",
       "       Gene_words  Variation_lbl_enc  Variation_len  Variation_words  \\\n",
       "count      8989.0        8989.000000    8989.000000      8989.000000   \n",
       "mean          1.0        4271.975971       5.742797         1.036823   \n",
       "std           0.0        2514.680898       3.070985         0.217404   \n",
       "min           1.0           0.000000       3.000000         1.000000   \n",
       "25%           1.0        2068.000000       5.000000         1.000000   \n",
       "50%           1.0        4259.000000       5.000000         1.000000   \n",
       "75%           1.0        6484.000000       5.000000         1.000000   \n",
       "max           1.0        8608.000000      55.000000         6.000000   \n",
       "\n",
       "            Text_len    Text_words  \n",
       "count    8989.000000   8989.000000  \n",
       "mean    59063.762042   8905.540550  \n",
       "std     37051.380894   5597.929867  \n",
       "min         4.000000      1.000000  \n",
       "25%     37955.000000   5700.000000  \n",
       "50%     53101.000000   8040.000000  \n",
       "75%     70410.000000  10598.000000  \n",
       "max    523393.000000  77202.000000  \n",
       "\n",
       "[8 rows x 3214 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if 2nd time run, comment above\n",
    "df_all= pd.read_csv('df_all.csv').drop(df_all.columns[0], axis=1)\n",
    "print(df_all.shape)#(8989, 3217)\n",
    "summary=df_all.describe()\n",
    "# summary.to_csv('summary.csv')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8989, 3213)\n",
      "(8989, 586)\n",
      "(8989, 2631)\n"
     ]
    }
   ],
   "source": [
    "df=df_all.iloc[:,4:]\n",
    "#df_std=df_all.std()\n",
    "print(df.shape)\n",
    "df_drop=df.loc[:, (df.std()< 0.001)]\n",
    "print(df_drop.shape)\n",
    "#print(df_drop.columns)\n",
    "dfnew=df_all.drop(df_drop.columns, axis=1)\n",
    "print(dfnew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8989, 2631)\n",
      "(3321, 2623)\n",
      "(5668, 2623)\n"
     ]
    }
   ],
   "source": [
    "df_all=dfnew\n",
    "print(df_all.shape)\n",
    "\n",
    "#remove all column which are 0s in train\n",
    "train = df_all.iloc[:len(train)]\n",
    "test = df_all.iloc[len(train):]\n",
    "\n",
    "train2=train.loc[:, (train != 0).any(axis=0)]\n",
    "print (train2.shape)\n",
    "\n",
    "test=test.loc[:, (train != 0).any(axis=0)]\n",
    "print (test.shape)\n",
    "train=train2\n",
    "\n",
    "# print(train.shape)\n",
    "# print(test.shape)\n",
    "# (8989, 2631)\n",
    "# (3321, 2623)\n",
    "# (5668, 2623)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use text information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        x = x.drop(['Gene', 'Variation','ID','Text'],axis=1).values\n",
    "        return x\n",
    "\n",
    "class cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        return x[self.key].apply(str)\n",
    "\n",
    "# # stop_words='english', #stop_words='stopWords',\n",
    "# train = fp.fit_transform(train); print(train.shape)\n",
    "# test = fp.transform(test); print(test.shape)\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as esw\n",
    "stopWords = [\"fig\", \"figure\", \"et\", \"al\", \"table\",  \n",
    "        \"data\", \"analysis\", \"analyze\", \"study\",  \n",
    "        \"method\", \"result\", \"conclusion\", \"author\",  \n",
    "        \"find\", \"found\", \"show\", \"perform\",  \n",
    "        \"demonstrate\", \"evaluate\", \"discuss\", \"google\", \"scholar\",   \n",
    "        \"pubmed\",  \"web\", \"science\", \"crossref\", \"supplementary\"] + list(esw) \n",
    "\n",
    "type(stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  how CountVectorizer work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# v = CountVectorizer(ngram_range=(1, 2))\n",
    "# print(v.fit([\"an apple a day keeps the doctor away\"]).vocabulary_)\n",
    "\n",
    "# v = CountVectorizer(ngram_range=(2, 2))\n",
    "# print(v.fit([\"an apple a day keeps the doctor away\"]).vocabulary_)\n",
    "\n",
    "# v = CountVectorizer(ngram_range=(1, 1))\n",
    "# print(v.fit([\"an apple a day keeps the doctor away\"]).vocabulary_)\n",
    "\n",
    "# v = CountVectorizer(ngram_range=(3, 3))\n",
    "# print(v.fit([\"an apple a day keeps the doctor away\"]).vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline...\n",
      "(3321, 2959)\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "(5668, 2959)\n"
     ]
    }
   ],
   "source": [
    "print('Pipeline...')\n",
    "\n",
    "fp = pipeline.Pipeline([\n",
    "    ('union', pipeline.FeatureUnion(\n",
    "        n_jobs = -1,\n",
    "        transformer_list = [\n",
    "            ('standard', cust_regression_vals()),\n",
    "            ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "            ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "            #commented for Kaggle Limits\n",
    "            ('pi3', pipeline.Pipeline([('Text1', cust_txt_col('Text')), ('tfidf_Text1', feature_extraction.text.TfidfVectorizer(stop_words=stopWords,ngram_range=(1, 1))), ('tsvd3', decomposition.TruncatedSVD(n_components=50, n_iter=25, random_state=12))])),\n",
    "            #commented for Kaggle Limits\n",
    "            ('pi4', pipeline.Pipeline([('Text2', cust_txt_col('Text')), ('tfidf_Text2', feature_extraction.text.TfidfVectorizer(stop_words=stopWords,ngram_range=(2, 2))), ('tsvd4', decomposition.TruncatedSVD(n_components=50, n_iter=25, random_state=12))])),\n",
    "            #commented for Kaggle Limits\n",
    "            ('pi5', pipeline.Pipeline([('Text3', cust_txt_col('Text')), \n",
    "                                       ('hv', feature_extraction.text.HashingVectorizer(stop_words=stopWords,decode_error='ignore', n_features=2 ** 18, non_negative=True, ngram_range=(3, 3))),\n",
    "                                       ('tfidf_Text3', feature_extraction.text.TfidfTransformer()), \n",
    "                                       ('tsvd5', decomposition.TruncatedSVD(n_components=200, n_iter=25, random_state=12))]))\n",
    "#             ('pi5', pipeline.Pipeline([('Text3', cust_txt_col('Text')), ('tfidf_Text3', feature_extraction.text.TfidfVectorizer(stop_words=stopWords,ngram_range=(3, 3))), ('tsvd5', decomposition.TruncatedSVD(n_components=50, n_iter=25, random_state=12))]))\n",
    "        ])\n",
    "    )])\n",
    "#if out of mempry, use the commented\n",
    "# fp = pipeline.Pipeline([\n",
    "#     ('union', pipeline.FeatureUnion(\n",
    "#         n_jobs = -1,\n",
    "#         transformer_list = [\n",
    "#             ('standard', cust_regression_vals()),\n",
    "#             ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), \n",
    "#                                        ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), \n",
    "#                                        ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "#             ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), \n",
    "#                                        ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), \n",
    "#                                        ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "#             #commented for Kaggle Limits\n",
    "#             ('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), \n",
    "#                                        ('hv', feature_extraction.text.HashingVectorizer(stop_words=stopWords,decode_error='ignore', n_features=2 ** 18, non_negative=True, ngram_range=(1, 3))),\n",
    "#                                        ('tfidf_Text', feature_extraction.text.TfidfTransformer()), \n",
    "#                                        ('tsvd3', decomposition.TruncatedSVD(n_components=300, n_iter=25, random_state=12))]))\n",
    "\n",
    "        \n",
    "#         ])\n",
    "#     )])\n",
    "\n",
    "\n",
    "train = fp.fit_transform(train)\n",
    "print (train.shape)\n",
    "\n",
    "test_t = np.empty([0, train.shape[1]])\n",
    "step = 500\n",
    "for i in range(0, len(test), step):\n",
    "    if i % 10 == 0: print(i)\n",
    "    step_end = i+step\n",
    "    step_end = step_end if step_end < len(test) else len(test)\n",
    "    _test = fp.transform(test.iloc[i:step_end])\n",
    "    test_t = np.vstack((test_t, _test))\n",
    "test = test_t\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if max(y)==9:\n",
    "    y = y - 1 #fix for zero bound array\n",
    "max(y) #fix for zero bound array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 2959)\n",
      "(5668, 2959)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# # np.savetxt('train2734.txt', train)\n",
    "# # np.savetxt('test2734.txt', test)\n",
    "# np.savetxt('train2959.txt', train)\n",
    "# np.savetxt('test2959.txt', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = np.loadtxt('train_629.txt')\n",
    "# test = np.loadtxt('test_629.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8989, 2959)\n",
      "(8989, 2959)\n",
      "(3321, 2959)\n",
      "(5668, 2959)\n"
     ]
    }
   ],
   "source": [
    "##feature selection by VarianceThreshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.00001))\n",
    "tr_te=np.concatenate((train, test))\n",
    "print(tr_te.shape)\n",
    "tr_te=sel.fit_transform(tr_te)\n",
    "print(tr_te.shape)\n",
    "\n",
    "# train1 = tr_te[:len(train)]\n",
    "# test1 = tr_te[len(train):]\n",
    "# print(train1.shape)\n",
    "# print(test1.shape)\n",
    "\n",
    "train = tr_te[:len(train)]\n",
    "test = tr_te[len(train):]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# np.savetxt('train2967.txt', train)\n",
    "# np.savetxt('test2967.txt', test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = 10#5\n",
    "imp = np.zeros((fold, train.shape[1]))\n",
    "\n",
    "for i in np.array(range(fold)):\n",
    "    rf = RandomForestClassifier(n_jobs=-1,n_estimators=50,oob_score=True,max_features=\"sqrt\", random_state=i)\n",
    "    rf.fit(train, y)\n",
    "    imp[i,] = rf.feature_importances_\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = range(train.shape[1])\n",
    "\n",
    "plt.plot(t,imp[0,],'r') # plotting t,a separately \n",
    "plt.plot(t,imp[1,],'b') # plotting t,b separately \n",
    "plt.plot(t,imp[2,],'g') # plotting t,c separately \n",
    "plt.plot(t,imp[3,],'y-') # plotting t,a separately \n",
    "plt.plot(t,imp[4,],'p-') # plotting t,b separately \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559\n",
      "1961\n",
      "1550\n",
      "811\n",
      "572\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGfCAYAAADYnUyNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26b7f4acc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(t,importances,'r') \n",
    "importances=sum(imp)\n",
    "importances_sort=np.sort(importances)[::-1]\n",
    "plt.plot(range(len(importances_sort)),importances_sort)\n",
    "print(sum(importances>0.00001))\n",
    "print(sum(importances>0.00005))\n",
    "print(sum(importances>0.0001))\n",
    "print(sum(importances>0.0005))\n",
    "print(sum(importances>0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.305722891566\n",
      "0.308242378623\n",
      "0.305984192699\n",
      "0.30109145653\n",
      "0.305231464057\n",
      "0.895726985073\n"
     ]
    }
   ],
   "source": [
    "# ##feature selection by tuning RandomForestClassifier\n",
    "# # Instantiate the CV and RF                                                                     \n",
    "# kf = KFold(n_splits=5, shuffle=True,random_state=0)                                                                          \n",
    "# # rf = RandomForestClassifier(n_jobs=-1,n_estimators=500,oob_score=True,max_features=\"sqrt\", random_state=0)\n",
    "# rf = RandomForestClassifier(n_jobs=-1,n_estimators=500,oob_score=True,max_features=0.4,max_depth=20, random_state=0)\n",
    "\n",
    "# preds1=np.zeros((train.shape[0],9))\n",
    "\n",
    "# #denom = 0                                                                                                \n",
    "# for tr_idx, te_idx in kf.split(train):                                                      \n",
    "#     # train                                                                                     \n",
    "#     rf.fit(train[tr_idx,:], y[tr_idx])                                              \n",
    "#     # predict                                                                                   \n",
    "#     preds1[te_idx,:] = rf.predict_proba(train[te_idx,:]) #predict(iris.data[te_idx])                                                        \n",
    "#     oob_error = 1 - rf.oob_score_\n",
    "#     print(oob_error)\n",
    "# #     pred = rf.predict_proba(test)\n",
    "# #     if denom != 0:        \n",
    "# #         preds += pred\n",
    "# #     else:        \n",
    "# #         preds = pred.copy()\n",
    "# #     denom += 1\n",
    "# # preds /= denom\n",
    "# # np.savetxt('test_preds_RF_fold_'  + str(denom) + '.txt', preds)\n",
    "# # np.savetxt('train_preds_RF_fold_'  + str(denom) + '.txt', preds1)\n",
    "# print(log_loss(np.array(y),np.array(preds1)))\n",
    "# #'train2734.txt'\n",
    "# #max_features=\"sqrt\" 0.9248\n",
    "# #max_features=0.1, 0.890869728693\n",
    "# #max_features=0.2  0.898875207776\n",
    "# #'train2959.txt'\n",
    "# #max_features=0.05  0.981296432429\n",
    "# #max_features=0.1, 0.944583962315\n",
    "# #max_features=0.2  0.930992481086 due to more % useful features\n",
    "# #max_features=0.3  0.928734055471\n",
    "# #max_features=0.4  0.912923241119\n",
    "# #max_features=0.5  0.914723769535\n",
    "# #####################\n",
    "# #max_features=0.4,max_depth=15, \n",
    "# # 0.909051901691\n",
    "# #max_features=0.4,max_depth=20, \n",
    "# #0.895726985073\n",
    "# #max_features=0.4,max_depth=25, \n",
    "# #0.895984051886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n",
      "0.00141003540008\n",
      "0.000315054610898\n",
      "0.0001110383038\n",
      "4.70963619111e-05\n"
     ]
    }
   ],
   "source": [
    "# importances_sort=np.sort(importances)[::-1]\n",
    "# plt.plot(range(len(importances_sort)),importances_sort)\n",
    "print(sum(importances_sort==0))\n",
    "\n",
    "print(importances_sort[500])\n",
    "print(importances_sort[1000])\n",
    "print(importances_sort[1500])\n",
    "print(importances_sort[2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PCA for dropped columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148,)\n",
      "[  9.99949338e-01   3.11836902e-05   2.70575548e-06   2.09089375e-06\n",
      "   1.95036698e-06   1.54813483e-06   1.44744215e-06   8.12541992e-07\n",
      "   7.00801148e-07   6.07232084e-07]\n"
     ]
    }
   ],
   "source": [
    "#min(indices)\n",
    "thres=0.0005\n",
    "ind_drop=indices[(importances<thres)]\n",
    "print(ind_drop.shape)\n",
    "\n",
    "print(train[:,ind_drop].shape)\n",
    "\n",
    "# from sklearn.decomposition import PCA, FastICA, TruncatedSVD\n",
    "# from sklearn.random_projection import GaussianRandomProjection\n",
    "# from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA   \n",
    "pca=PCA(n_components=10)  #PCA(n_components='mle') \n",
    "newtrain=pca.fit_transform(train[:,ind_drop])  \n",
    "print(pca.explained_variance_ratio_)  \n",
    "#for test, apply same pca\n",
    "newtest=pca.transform(test[:,ind_drop])  #newtest=pca.fit_transform(test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3321, 2959)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # train_full=train\n",
    "# # test_full=test\n",
    "train=train_full\n",
    "test=test_full\n",
    "\n",
    "train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 811)\n",
      "(5668, 811)\n"
     ]
    }
   ],
   "source": [
    "select_column=indices[0:sum((importances)>thres)]\n",
    "train=train_full[:,select_column]\n",
    "test=test_full[:,select_column]\n",
    "# train=np.concatenate((train_full[:,select_column], newtrain),axis=1)\n",
    "# test=np.concatenate((test_full[:,select_column], newtest),axis=1)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "# np.savetxt('train671.txt', train)\n",
    "# np.savetxt('test671.txt', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # np.savetxt('train678.txt', train)\n",
    "# # np.savetxt('test678.txt', test)\n",
    "# np.savetxt('train811.txt', train)\n",
    "# np.savetxt('test811.txt', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd RF with fewer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.302710843373\n",
      "0.307866014302\n",
      "0.301844185171\n",
      "0.299962363568\n",
      "0.298833270606\n",
      "0.891789433695\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True,random_state=0)                                                                          \n",
    "# rf = RandomForestClassifier(n_jobs=-1,n_estimators=500,oob_score=True,max_features=\"sqrt\", random_state=0)\n",
    "rf = RandomForestClassifier(n_jobs=-1,n_estimators=500,oob_score=True,max_features=0.25,max_depth=15, random_state=0)\n",
    "\n",
    "preds1=np.zeros((train.shape[0],9))\n",
    "\n",
    "#denom = 0                                                                                                \n",
    "for tr_idx, te_idx in kf.split(train):                                                      \n",
    "    # train                                                                                     \n",
    "    rf.fit(train[tr_idx,:], y[tr_idx])                                              \n",
    "    # predict                                                                                   \n",
    "    preds1[te_idx,:] = rf.predict_proba(train[te_idx,:]) #predict(iris.data[te_idx])                                                        \n",
    "    oob_error = 1 - rf.oob_score_\n",
    "    print(oob_error)\n",
    "#     pred = rf.predict_proba(test)\n",
    "#     if denom != 0:        \n",
    "#         preds += pred\n",
    "#     else:        \n",
    "#         preds = pred.copy()\n",
    "#     denom += 1\n",
    "# preds /= denom\n",
    "# np.savetxt('test_preds_RF_fold_'  + str(denom) + '.txt', preds)\n",
    "# np.savetxt('train_preds_RF_fold_'  + str(denom) + '.txt', preds1)\n",
    "print(log_loss(np.array(y),np.array(preds1)))\n",
    "#'train671.txt' max_features=0.1\n",
    "#0.895365186154  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n",
      "528\n",
      "463\n",
      "375\n",
      "363\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAGfCAYAAAAkiGdHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VPW9//HXJ5OVhLCGHQQVF9QKiIhLtWpbAXuLbW2v\nti619lq92mtve9vSfbOtt61d7LVSt1+1tdpF75VaqiJgxQ0BRQUECfsSSFgTsi/f3x9zZnIymSQT\nsg1+38/HIw9mzvmeOd+h1He+3/NdzDmHiIjIu11GX1dARESkNyjwRETECwo8ERHxggJPRES8oMAT\nEREvKPBERMQLCjwREfGCAk9ERLygwBMRES9k9nUFOmPo0KFu/PjxfV0NERFJIytXrtzrnCvqqNxR\nFXjjx49nxYoVfV0NERFJI2a2NZVy6tIUEREvKPBERMQLCjwREfGCAk9ERLygwBMRES8o8ERExAsK\nPBER8YICT0REvKDAExERLyjwRETECwo8ERHxggJPRES8oMATEREvKPBERMQLKQWemc00s/VmVmxm\nc5OcNzO7Mzj/pplNDY7nmtmrZvaGma0xs++FrhlsZgvNbEPw56Du+1ptq2tooqquoTduJSIiaaTD\nwDOzCHAXMAuYBFxpZpMSis0CJgY/NwB3B8drgYucc6cDk4GZZjYjODcXWOScmwgsCt73uCvueZlJ\n3366N24lIiJpJJUW3nSg2Dm3yTlXBzwKzEkoMwd4yEW9Agw0s5HB+8NBmazgx4WueTB4/SBwWVe+\nSKpe23awN24jIiJpJpXAGw1sD73fERxLqYyZRcxsFVAKLHTOLQvKDHfOlQSvdwPDk93czG4wsxVm\ntqKsrCyF6oqIiLTW44NWnHONzrnJwBhgupmdmqSMo7nll3juHufcNOfctKKioh6urYiIvFulEng7\ngbGh92OCY50q45w7CCwBZgaH9pjZSIDgz9LUqy0iItI5qQTecmCimU0ws2zgCmB+Qpn5wDXBaM0Z\nwCHnXImZFZnZQAAzywM+AKwLXXNt8Ppa4IkufhcREZE2ZXZUwDnXYGa3AE8DEeAB59waM7sxOD8P\nWADMBoqBKuC64PKRwIPBSM8M4M/OuSeDc7cDfzaz64GtwCe672uJiIi01GHgATjnFhANtfCxeaHX\nDrg5yXVvAlPa+Mx9wMWdqayIiMiR0korIiLiBQWeiIh4wavAi/a8ioiIj7wKvNqGpr6ugoiI9BGv\nAq9JLTwREW95FXj9sjO5asY4Budn93VVRESkl3kVeACG9XUVRESkD3gXeKDBKyIiPvIu8EwNPBER\nL3kXeNDGtgwiIvKu5l3gqYEnIuIn7wIPQI/wRET8413gmR7iiYh4ybvAExERP3kZeJqWICLiHy8D\nT0RE/ONl4Kl9JyLiH+8CT2NWRET85F3gAWriiYh4yLvA0+LRIiJ+8i7wQA08EREfeRd4eoYnIuIn\n7wIPNA9PRMRH3gWeGngiIn7yLvBAz/BERHzkXeDpGZ6IiJ+8CzzQ9kAiIj7yLvC0PZCIiJ+8CzwR\nEfGTl4HnNGxFRMQ73gWeOjRFRPzkXeCBBq2IiPjIv8BTE09ExEv+BR6aeC4i4iPvAk/bA4mI+Mm7\nwAPUxBMR8ZB3gad55yIifvIu8EDz8EREfORd4KmBJyLiJ+8CDzQPT0TER94Fnp7hiYj4ybvAAw3S\nFBHxkXeBp3l4IiJ+8i7wRETET14GntOoFRER73gXeBq0IiLiJ+8CDzRoRUTER94Fnhp4IiJ+Sinw\nzGymma03s2Izm5vkvJnZncH5N81sanB8rJktMbO1ZrbGzG4NXfNdM9tpZquCn9nd97Xap0d4IiL+\nyeyogJlFgLuADwA7gOVmNt85tzZUbBYwMfg5C7g7+LMB+JJz7jUz6w+sNLOFoWt/4Zz7Wfd9nRTo\nIZ6IiJdSaeFNB4qdc5ucc3XAo8CchDJzgIdc1CvAQDMb6Zwrcc69BuCcqwDeBkZ3Y/1FRERSkkrg\njQa2h97voHVodVjGzMYDU4BlocOfD7pAHzCzQSnWuUvUvhMR8VOvDFoxswLgMeALzrny4PDdwLHA\nZKAEuKONa28wsxVmtqKsrKzb6qS5eCIifkkl8HYCY0PvxwTHUipjZllEw+5h59zjsQLOuT3OuUbn\nXBNwL9Gu01acc/c456Y556YVFRWlUN326RGeiIifUgm85cBEM5tgZtnAFcD8hDLzgWuC0ZozgEPO\nuRIzM+B+4G3n3M/DF5jZyNDbjwCrj/hbHAE18ERE/NLhKE3nXIOZ3QI8DUSAB5xza8zsxuD8PGAB\nMBsoBqqA64LLzwWuBt4ys1XBsa875xYAPzGzyUTngW8BPtdt36odWjxaRMRPHQYeQBBQCxKOzQu9\ndsDNSa57gTbGiTjnru5UTUVERLrAu5VWYtSjKSLiF+8CT4NWRET85F3gxWhagoiIX7wLPDXwRET8\n5F3gxah9JyLiF+8CT8/wRET85F3gxegRnoiIX7wLPFMTT0TES94FXozTUzwREa94G3giIuIXbwNP\nz/BERPziXeDpEZ6IiJ+8CzwREfGTd4Gn7YFERPzkXeCJiIifvA08DVoREfGLd4GnQSsiIn7yLvBi\nNPFcRMQv3gWeGngiIn7yLvBi9AxPRMQv3gWenuGJiPjJu8CLUQNPRMQv3gWeJp6LiPjJu8CLcXqI\nJyLiFe8CT8/wRET85F3gxew8WN3XVRARkV7kbeDN/OXSvq6CiIj0Im8DT0RE/OJd4Jke4omIeMm7\nwBMRET8p8ERExAveBZ46NEVE/ORd4ImIiJ+8CzyNWRER8ZN3gSciIn7yLvDUwBMR8ZN3gSciIn7y\nLvA08VxExE/eBZ6IiPjJu8BTA09ExE/eBZ6IiPjJu8BTA09ExE/eBZ6IiPjJv8DTQzwRES/5F3gi\nIuIlBZ6IiHjBu8BTh6aIiJ+8CzwREfGTd4GnMSsiIn5KKfDMbKaZrTezYjObm+S8mdmdwfk3zWxq\ncHysmS0xs7VmtsbMbg1dM9jMFprZhuDPQd33tURERFrqMPDMLALcBcwCJgFXmtmkhGKzgInBzw3A\n3cHxBuBLzrlJwAzg5tC1c4FFzrmJwKLgfY8zPcUTEfFSKi286UCxc26Tc64OeBSYk1BmDvCQi3oF\nGGhmI51zJc651wCccxXA28Do0DUPBq8fBC7r4ncRERFpUyqBNxrYHnq/g+bQSrmMmY0HpgDLgkPD\nnXMlwevdwPBkNzezG8xshZmtKCsrS6G67dMzPBERP/XKoBUzKwAeA77gnCtPPO+cc4BLdq1z7h7n\n3DTn3LSioqIerqmIiLxbpRJ4O4GxofdjgmMplTGzLKJh97Bz7vFQmT1mNjIoMxIo7VzVj4waeCIi\nfkol8JYDE81sgpllA1cA8xPKzAeuCUZrzgAOOedKLLq9+P3A2865nye55trg9bXAE0f8LURERDqQ\n2VEB51yDmd0CPA1EgAecc2vM7Mbg/DxgATAbKAaqgOuCy88FrgbeMrNVwbGvO+cWALcDfzaz64Gt\nwCe672u1Tc/wRET81GHgAQQBtSDh2LzQawfcnOS6F2ijF9E5tw+4uDOVFREROVLerbQiIiJ+8i7w\nNPFcRMRP3gWeiIj4yb/AUwNPRMRL/gWeiIh4ybvAUwNPRMRP3gWeiIj4ybvAM808FxHxkneBJyIi\nfvIu8NS+ExHxk3eBJyIifvIu8PQIT0TET94FnoiI+Mm7wFMLT0TET94FnoiI+EmBJyIiXvAu8LQ9\nkIiIn7wLPBER8ZN3gadBKyIifvIu8ERExE8KPBER8YICT0REvOBd4Gl7IBERP3kXeCIi4ifvAk/t\nOxERP3kXeCIi4ifvAk+P8ERE/ORd4ImIiJ+8CzytpSki4ifvAk9ERPykwBMRES94F3gatCIi4ifv\nAk9ERPzkXeCpgSci4ifvAk9ERPzkXeDpGZ6IiJ+8CzwREfGTh4GnJp6IiI88DDwREfGRd4EXfobn\nnOu7ioiISK/yLvDClHciIv7wLvDCT/CUdyIi/vAu8MLUpSki4g/vAs80EU9ExEveBV6Y2nciIv7w\nO/CUeCIi3vAu8FoOWlHiiYj4wrvAC1MLT0TEHykFnpnNNLP1ZlZsZnOTnDczuzM4/6aZTQ2de8DM\nSs1sdcI13zWznWa2KviZ3fWvk8p36Y27iIhIuukw8MwsAtwFzAImAVea2aSEYrOAicHPDcDdoXO/\nA2a28fG/cM5NDn4WdLLuXaYWnoiIP1Jp4U0Hip1zm5xzdcCjwJyEMnOAh1zUK8BAMxsJ4Jx7Htjf\nnZXuCrXwRET8lErgjQa2h97vCI51tkwynw+6QB8ws0HJCpjZDWa2wsxWlJWVpfCRqdOgFRERf/Tl\noJW7gWOByUAJcEeyQs65e5xz05xz04qKirp8UwuN01SXpoiIP1IJvJ3A2ND7McGxzpZpwTm3xznX\n6JxrAu4l2nXaq5R3IiL+SCXwlgMTzWyCmWUDVwDzE8rMB64JRmvOAA4550ra+9DYM77AR4DVbZXt\nVtoeSETES5kdFXDONZjZLcDTQAR4wDm3xsxuDM7PAxYAs4FioAq4Lna9mT0CvA8YamY7gO845+4H\nfmJmk4k2tLYAn+vG75USxZ2IiD86DDyAYMrAgoRj80KvHXBzG9de2cbxq1OvZvfRIE0RET9ppRUR\nEfGC14GnPk0REX94F3jh/fA0D09ExB/eBV6YujRFRPzhXeCFpyIo70RE/OFd4IVpHp6IiD+8DjwR\nEfGH14Gn9p2IiD/8DjwlnoiIN/wOPLXxRES84V3guTbfiIjIu5l3gRemvBMR8YfXgSciIv7wOvA0\naEVExB/+BZ4Lv1TiiYj4wrvAC4ecWngiIv7wLvDClHciIv7wO/DUxBMR8YbngdfXNRARkd7iXeAp\n5ERE/ORd4ImIiJ+8Djy19kRE/OF34GmcpoiIN7wLvHCrTi08ERF/eBd4Yco7ERF/eB14IiLiD68D\nTxPPRUT84V3guTZei4jIu5t3gRemBp6IiD+8Djy18URE/OFd4IWf26mFJyLiD+8CL0x5JyLiD68D\nT0RE/OF14KlLU0TEH94FXstpCUo8ERFfeBd4YWrhiYj4Q4EnIiJe8Dvw1KUpIuIN7wJPrToRET95\nF3hhCj8REX94HXgiIuIPrwNPLTwREX94GHihtTQ1aEVExBseBl4ztfBERPzhdeA19ULizfvnRs69\nfXGP30dERNqX2dcV6G3hjGts6vnAu/0f63r8HiIi0jGvW3i9EXgiIpIevAu8cMQp8ERE/JFS4JnZ\nTDNbb2bFZjY3yXkzszuD82+a2dTQuQfMrNTMVidcM9jMFprZhuDPQV3/Op3ToMATEfFGh4FnZhHg\nLmAWMAm40swmJRSbBUwMfm4A7g6d+x0wM8lHzwUWOecmAouC972qUcM0RUS8kUoLbzpQ7Jzb5Jyr\nAx4F5iSUmQM85KJeAQaa2UgA59zzwP4knzsHeDB4/SBw2ZF8ga5obFTgiYj4IpXAGw1sD73fERzr\nbJlEw51zJcHr3cDwFOrSZS1GaaqFJyLijbQYtOKcc5B82RMzu8HMVpjZirKysm69rwatiIj4I5XA\n2wmMDb0fExzrbJlEe2LdnsGfpckKOefucc5Nc85NKyoqSqG6qVPgiYj4I5XAWw5MNLMJZpYNXAHM\nTygzH7gmGK05AzgU6q5sy3zg2uD1tcATnah3t1DgiYj4o8PAc841ALcATwNvA392zq0xsxvN7Mag\n2AJgE1AM3Av8e+x6M3sEeBk40cx2mNn1wanbgQ+Y2Qbg/cH7HhdeMFrTEkRE/JHS0mLOuQVEQy18\nbF7otQNubuPaK9s4vg+4OOWa9oAmBZ6IiDfSYtBKX+nNFp7TiFARkT7lXeD11bQE5Z2ISN/yLvDC\nGhubeu1evbEVkYiItM3vwOvFDFLciYj0Le8C79zjh5IVMQAam3qvhacGnohI3/Iu8AbnZ/PWdy8B\nennQitp4IiJ9yrvAA4hkRFt4vTktQS08EZG+5WfgWTTwNPFcRMQfXgZeRoZhphaeiIhPvAw8gMwM\n0zM8ERGPeBt4kQzr1Ynn6j0VEelb/gaeWa/ueK6lxURE+pa/gdfrXZoiItKXvA28zEhGry73pQae\niEjf8jbwMqx3W3hq4omI9C1vAy8zw3p3WoIST0SkT3kbeL3+DE95JyLSp7wOvN5t4YmISF/yNvAy\nI0ZdL+6HV1XX0Gv3EhGR1rwNvOxIBg29OA/vvP9ewtINZb12PxERacnbwMuKZPRqCw/g5Y37evV+\nIiLSzOPAM+qDwHt27R7Gz/07uw/V9HGtRESkp3gceBnUNUQD7+FlWwFYs+tQj94zI9iWSEREep+3\ngZed2dylGXuUlxhI3b3+pfJORKTv+Bt4kQzqG5u49dHXef6d6GCSjIzmRPrdi5uZ8LUF1NQ3AlBa\nXsMb2w926Z7KOxGRvuNt4GVFMli9s5wnVu2KHwvlHX9esQOAZ9buAeDCnz3HnLte7NI9TU08EZE+\n423gZST55uEezOOGFQDRlh1AZV1jl++pvBMR6TveBl6yOXj1oWkKsed31d0QdDGmTk0RkT6T2dcV\n6CvJ1tGsb2xiwVslHKiqiwdidX03Bp7yTkSkz3gbePVJJp3XNjRx66OrADh2aD7QzYHXbZ8kIiKd\n5W2XZmPSFl7zsU17KwHiozSTufKeV/jEb19O+Z7hUaAiItK7vG3hJevSjE1ED6uua2wz9F7epKXC\nRESOFt628BqSdGmW19S3OlZd38hJ33oq/r6tLYX+8VZJfMUWERFJP2rhhZQcrG51rLq+ZTA2OkdG\nkqdxNz38GgCfOuuYNu+ppcVERPqOxy281oG3K8ni0TUJ0xKSPftr7zlfmPJORKTveBt4yYJrV9IW\nXsswa0qyvubBqtZdocko70RE+o63gXfHJ05vdawkoYV30oj+rXYqTxaUh6pTCzx1aYqI9B1vA+/U\n0QP46JTRLY7tr6xr8f6MYwZRWlHb4lhTkj1jk43uTEZ5JyLSd7wNPIhuEZRoQF5W/PWogXlU1ERb\neIP6RY83Bl2a+w43B2F37JxeVlHLU6tLuvw5IiKSnNeBlxME3lUzxnHMkH4AFPXPiZ8fOSA3/npg\nv2yguUvz3P9eHD+XbIpDZ13zwKvc+IfXqKxt6LiwiIh0mrfTEgBysiIAZGZkMGXsQLbuq2JoQTY3\nXnA6wwtzyAxtqRALx9iglZrQdIVkUxw6a/v+KqC5BSkiIt3L6xZebhB4GWZMPWYQEG3BXX7GGN47\nsYgThhe0Kpts0EqqXZrKMhGRvuN14PXLjoZYfWMTJ48sBKLP0mKGFDR3b+ZmRf+qkgVesjl9ySSb\n0pBIoSgi0jO8Drz8UOCdMLw/AGcfN6RFmdgzvbyghZcstMLP8FbvPMRPn16Hcy7eTRnTXndlbP89\np8QTEekRXj/Dy8uOfv26hiYG5GXxzy+/jxGhgSrQ3LJLtUvzI795kfpGx3++/wT+7aEVLcqlkmXJ\nPl9ERLrO68CLTUuoDQLrmCH5rcrkZEaDLrfdFl7zsVhgNTS51qu0tBNmsTPKOxGRnuF1l2Z2JPr1\n25s4Hhud2dzCg9ueXNuiTENoNroFs8uTDWRJJcxSec4nIiKd53XgxcKsvcCLBV2sbGOT474XNrco\nUxu6PraYSrKBLKmEmQJPRKRneB142SkFXsvRmU3OtVqhpTq0o0IsruqTtvBSCbwOi4iIyBFIKfDM\nbKaZrTezYjObm+S8mdmdwfk3zWxqR9ea2XfNbKeZrQp+ZnfPV0pdPPDamUcXe4YX67b80K9fIDch\n8KpCgRcLtWQh2l7gxU6195xPRESOXIeBZ2YR4C5gFjAJuNLMJiUUmwVMDH5uAO5O8dpfOOcmBz8L\nuvplOmtEYXRE5rRg0nkyF588DIDxoQEtsRVaYsI7KsSCq6HJtRqVGcuylVsPsGzTvqT3U5emiEjP\nSGWU5nSg2Dm3CcDMHgXmAOGRG3OAh1x0EtkrZjbQzEYC41O4ts+MHdyPxV+6gHGD+7VZ5pPTx3HJ\nKSNYs6s8fizWzRlTVdd6A9j2ujQ/dvdLAGy5/dJWZTQtQUSkZ6TSpTka2B56vyM4lkqZjq79fNAF\n+oCZJW1mmdkNZrbCzFaUlZWlUN3OObaogMxI238NZsbQghwiob19wmtsQstneDHJAq+9xpsj9oyw\noxqLiMiR6MtBK3cDxwKTgRLgjmSFnHP3OOemOeemFRUV9Wb9Wghn3Oa9lS3O1TQkC7wkozRTSDN1\naYqI9IxUujR3AmND78cEx1Ipk9XWtc65PbGDZnYv8GTKte4DkXZ2bw3vnBCTrIXX/tJi0T8VeCIi\nPSOVFt5yYKKZTTCzbOAKYH5CmfnANcFozRnAIedcSXvXBs/4Yj4CrO7id+lRkYy2A682aQuvc12a\nMXqGJyLSMzps4TnnGszsFuBpIAI84JxbY2Y3BufnAQuA2UAxUAVc1961wUf/xMwmE526tgX4XHd+\nse6W0U7gJW/hufhzuZh2pyXE/lTeiYj0iJTW0gymDCxIODYv9NoBN6d6bXD86k7VtI+136XZuoWX\nbBf0uoYmTvn2U+3eR12aIiI9w+uVVjojo53AS3WU5v7KOiqTlA1Tl6aISM9Q4KWovqnt1ViSzcOr\na3QYLUMyMcrW767g4WVbgeYRnMo7EZGe4fX2QJ1R3856m5WhlVZiknVpJk5LuOSXzwdlHQ2htTpF\nRKT7qYWXooZ2ml5tdWkmDlqpb+MzvjN/Tfy11tIUEekZCrwUFeZmtXkuWRjWJZl43l4rMaa9uXoA\nZRW1HKqu7/BzRESkJQVeik4bM4CHPjM95fLJujQb2nkOGNNRj+aZP3yW6T98NuV6iIhIlJ7hdcL5\nJ6S+tNl9Sze32BgWkrf6EqUySjPxc0VEpGMKvB6y82B1q2OpdGlq0IqISM9Ql+YR+sbskzt9TbK5\neYmUdyIiPUOBd4SyMzv/V5dK4GniuYhIz1CXZiddfNIwJgzNp52FV9qUbMugROrSFBHpGQq8Trr/\n02cC8NDLWzp9bSotPAWeiEjPUJfmETqCBl67k9dj+qJH897nN/GHV6JLnD29ZnfSxbBFRI52auH1\nov2VdR2WaWxyLHirhKL+OZw5fnAv1Ap+uOBtAE4a0Z/P/X4lnz5nPN/98Cm9cm8Rkd6iFl4Xfeqs\ncfHX7WyZl7J39lTw7w+/xsfnvdz1D0uitKKGt0vKk56LreCyfX9Vj9xbRKQvKfCOVDBqJdwDWZDT\n9QbzrxcXd/kz2nPhT59j1q+WJj0XG4iTrFf172+WsPtQTc9VTESkhynwutGRTFXobe3txxfbzsgl\nDJypa2ji5j++xpX3vtKjdRMR6Unp/1/oNBXrvQxnQ6Q7+jRDnHM459i+v4r7X9jc4lyPzNdro4VX\nF4wuVVeniBzNNGilG2VmtP37w6gBuezqZJfgJ+9dxvIt+xk/NJ/i0sN8+PRR8XML1+6h5FA11507\n4Yjr25bELI0tiaYpEyJyNFPgdaPMSNstvJysSKc/7+VN+wAoDwaT3Pb3tfFzN/5hJUCLwNu2r4px\nQ/ql9NnOOSxh9nxDMDG+VZdm0MJT3InI0UxdmkeoOSuaYyCznS7NI1mZJSbWVfrEql1tlnlqdQnn\n/3QJz60vjR/76l/fjM+vSzT1Bwu5KQjNmLo2FreOHVcDT0SOZgq8I2RJpp5nRdr+68zoQuKlcu2S\ndWUAbD/QvEvDn1Zs55v/tzpp+QNV9fxj9e4Wx2IrwSQGm7YjEpF3AwVeF6U6aKWj8SwfP2NMm+fa\ny7tdB6v5/ctbKCmPPh8c1C+6M3uyDWiTCXdffuFPq6LHEjovw0uipTJ5XkQkHSnwjlAswMJh1F6X\nZkettH89c2yb59rrSvzZ0+v51hNreP6daAvvnT2HeeTVbRyoqm/3fjHJFrROvF+4q3PqDxam9Lki\nIulGgXeELpsymivOHMuXLzkpfixZC2/eVVOBloE3ckBuizInjejPiSP6t3mvunZaawerWwbbnYs2\n8LXH32JT2eH2v0D8+tYttsTRmO3dvyte2bSPsorapOcu+OmSVlMxuuLnC9/p1s8TkaOPAu8I5WZF\nuP1j72Fwfnb8WOKoR4DCvGgXY3jGwgUnFLUoY2btdoe2t8vC4nWlSY8v37K/1bETv/mPVsfO/8mS\nVscSW3ip7NQes7+yjpeK91JZ28D/LN5AfWMTr287wBOrdrYqe8U9r3D5vJcAWPT2HopLK4L7O7bu\nq+IHT65tdc2RunPRhm79PBE5+ijwulEss746s7nVlxdMR4iEwjCxxTTzlBHtdnl2JnBinnyzJP56\nxZb9VNU1JB18UlPf+lhiJ2dtQn2Xbihr876f+d1yPnnfMhau3cPPnnmH17cd5Bv/u5pbH13FG9sP\nxsvFukm37otOZr/+wRW8/+fPt1knEZGuUuB1o9jIzanjBsaPxcIj3PqbMm5Q/HX/3Ew+f9Hx5GRm\nMKx/TtLPbW85sLas210Rf335vJd5+JVtKV+bbGmxsKvvf5WFa/dw+d0vtVp9ZW2wMHVxabRLtbSi\nhh0HomVKQhPvq0PfqSlhpntlXUOL9/WNTa3KhN25aANn/vDZdr+TiIgCrzu1s/hydmjKwmWTR/HS\n3Iv4w/VnseiLF5CRYZgZL829qMeqFtsCKBUVNQ08sWonH/r1UpqaXNL5eV997E1WbD3AvH9ubHE8\nNnAnHnjlzc/oqkJBVlXf/LqitmXAVdW2DPiJ3/gH1z+4vM36/nzhO5RV1LYKahGRMAVeNzjjmGiL\n7YThBQAU5mZx5vhBnDKqkMljBvJv753AL66YHC+fmZHBqIF5nDdxKMMKmwewZLYzjw/guKL8VseG\nFmQzemBed3yNuJ0Hqrn10VWs3lnO+j0VSZ8hxqYnFOS2XKwn9ixyYzBopuxwbfyZ4Ja9lfHQqwq1\n8MoTBt4ktvAAlqxvuxs1pq35gu21DkXEH1parBs8/NmzqKxtID8nk0tOGcGkUYX85cZz4ue/cekk\nAHKzMqipbzqiVVdmnzaCrEgGG8sqWxy/+6oz+M2SYnYerG7jys4Lt7juXLSBnHZ2gSjIbv4ntHjd\nHipqotcgMOuBAAAXTklEQVQWlzW38GJxc+fiYl7ZtJ+Hrp/OgdB8vtg+fLG/l3BLsK3VX5LWu6aB\n3OCZ6csb9+Gc45zjh1Id2sF9+/4qdh6sZsaxQ1L+XBF5d1DgdYPcrEj8P7TvnVjUZrnHbzqXBW+V\ntBsgbWlscuRmtkzKm953HGeOH8wvr5jC3sO1XHzHPzv9uYmyItZibl7iaiyJGkKtp7+u3BF/HWvV\nlVbUtNjZ4dUt+7nwZ8+1eJ73r7+NbnabH4RnZahL8yO/ebHNe8dGdcYcrm2gqH8Ozrn4VkZbbr+0\nRWvyvcGo1C23X8pLG/dy/LAChvVvOU2kLUs3lFFe3cDJI/vz0sZ98dbsldPHdXCliKQDBV4vmjSq\nkEmjCjt1zftOLOK59WXkZEbISJi68F8fPBGAAXlZDMjL4pJThvP0mj1dquOzX7yAC376HADHFuWz\nKaFFmehw0BrcebCaBW+1DselG/a2OlaSsGtEbFDO4doGLr/7JY4rKoifW7OreXf2l4r3cvZxQ+ID\ngGKjOuN1qWngmTW7ueH3LdcITTbX72BVHZ+8dxmjB+bx15vOZuSAlt3C9Y1NNDY5siIZ8WC7+v5X\ngehGv4dDrWAFnsjRQc/w0szPP3E6P7js1Pj7H33kNK47dzw/mHNqi6kN0Hqi+2+vnpb0M1/sYDDM\nP7/8vvjrgf2ymTw2Osp01qkjOGvCYD5+xpgWu7kPLWgeTVpZ20BDYxMX3/Fc/Nj7Tx7e7v3as2Lr\nAf60YnvSc5+8bxl/WbmDnzy1Lumi2BW19a3CDuBDv269w/v0Hy0CokF99o8XU1ZRy/w3duGco7ah\nkYvueI6TvvUUx319ASu27Ke8pvk54+GEQTbf/9taVm5tOe+xobEp5eXdRKR3qIWXZj46Nbqm5pJ1\npSxeV8qogXl8519OAWjVwktm449m89jKHXzlsTf5yJTRfPPSkxlSkHy6w7yrpjL/jV0U5mbFj/XL\njsSfuR0zJD++ksycyaO56v5lQHTaxcayw2wsq2TxulLe3Hmoxdy5syYM5tm3u9bShGigJ250+5W/\nvtlm+cra1tM39pTXtNrfD1o/G/zO/NXxFup/PPJ6i3PLtxzgtr+3Pcr1gRc388CLm3n7+zPJy47g\nnOP9P/8nmZEMnv3iBTy1uoSt+6o4cUR/3nfiMADe2VNBQU4mo7p5wJGItE2Bl6Z+86mprUYvdjCI\nMyhj8cEfZiQNuyunj6OoIJuZp45k5qkjqW1oDoqsSEb8AVxhaATmuccPYXhhDnvKaxk3uB/3XDON\n8XP/TmlFLR/9zUvxcmMG5TEgWF0mWWClamC/LF7/1gf4+v+u5pFXU5tDuKe89Qa7//7waynVJRZ2\nr2870OpcbUMjq0KT5tty+veeYfk33s+vFm1gSzChftu+Km78w2vxMn+75TxOGzOAD/4i2h275fZL\nO/xcEeke6tJMU7lZkRZTFiD1LYbik9xD/30PL2f2gzmn8MXg+R+0nCMYFm75mRmP3XQOYwfnce05\n44Ho88WwN77zQZ7+wvnxrtbYPS8/YwyP3XQOV05vXiD72rOPaTFBP9GAvCzMjB9/9DRuvXhiO9+2\nWbKtkFZujQbYd/9lUvzYO7fNalHmvOOHkh0MJPp/L26JH//jZ88C4JfPbkjp/nWNTZz+/Wd44MXm\nNTvP/2nLpdu2JUzUF5Heo8A7isQCb8ygPJ64+dw2y8ViMdyeefAz09ly+6Vsuf3SVvP9EtcAjV2X\nl91yl/Yxg/qx9CsXMXZwdFf1n15+evzc0q9cyIC8LPJzMuOBNzAvi6VfuZDbLjuVM44Z1GKFmS9+\n8EQeu+kcnv3iBRT/cBaXnBJ97hebU3js0OY5h+H1SgE+NrXlVkqzTxsRfx17fjhhaD7f/tAkhhfm\n8OlzxvPBU6Jl8rMj8XAD+MiU0fz++ums/8FMEsXWQY0ZkfALSOL7VNz8x9c458eLOn2diHSdujSP\nIrEgufbs8Zw+tu3WUSyQJo1MfUTo2MF5fHBSNBRiUwo6alEOCQVR7J4AM08dwcc2jOErM09keCgU\nYuuKDuyXFe/2PH5YdERmbNL4hyePouRgdXzuIsB7xgxocd8Zxw7mvIlDWPDWbhau3cOZ4wczZewg\ndh6s5jv/Mok7nnmHy6aM5vhhBXzmvAnx62677FROCUbJvjj3IvplRRgU+g6TRhbGl0Yb1C+Lk0cW\n8vvrp/Od+WvYVFbJ76+fzgeCrsi7PzWVU0cPiE9ziP197AvmFx47NJ87PnE6S9aV8uDLW/nmpSfz\n2+c3UVx6mF2HWne9ikjPU+AdRWKB19jBElrTJwzmb7ecF/+PeyqWfqV5JOdPP/4efrHwHU7uIDBj\ng2hiK83E5GZFuOMTp7cqHwu8ZDEaW81l7KB+LRbfBjhlVDTwvvWhSYwZlMcHTh5ORoYxsF82C9fu\n4dzjh3LC8Obtlf7rkhNJ5qoZx8RfJ1ud5qHrp/Pe/15CdX0jt112GpEM470Ti3jq1vPZfqCK44oK\n2PSj2WzbX8X4ofktngku+tIFHFdUwK6D1Zxz+2ImDM1nyrhoqzbWfZydmcGtj65KWjcR6XkKvKNI\nrBU1vDD5qMuw0xJaRZ1x0ojCNqc4JFrzvUuiA11SkNhFGlbfEA2P/JzWZbIzM5IO7rjwxGFs+tHs\nlEavpmJoQQ4fnzaGh17eSkNT8yjO7MyM+NzAjAxjfNDdGp4WEjs/amAeD3x6GlPHtfwlAODc44d2\nSz1F5Mgo8I4in5o+jtEDc7kwGNqeDvJzUv8nlJsVDcZk7dPYFkT9sjv3T7K7wi7my5ecSEGwRFwq\nnvz8eQwpaPmM8aKTks9DHFqQw//dfC6X3dW8eswza3bHny+KSM/SoJWjSEaGcdFJw5NuNHs0iC2/\nlkxsz7/8dlqBvaF/bhZfmXlSu3UNO3X0gFartLTn9ISW9w2/X0lphZ7pifQGBZ70mvae4cU2xe3X\niRbj0SjZLyvTf9j+qM0Xi/fy8XkvaeUWkS5S4Emvaa/VVJcmLby+sm53eas1P0vLowtv/+efVrF8\nywG2ag6fSJco8KTXtDe4JTZKs72BLe9mM3+5lA//zwtAdMf5TWWHmf6jRdzxzPp4mfBuGNV1jew7\n3HpRbBFpmwJPek3/YKmyz7732FbnYi28nEw/Aw+iu0jM+tVSPv/I61wUhNtTa3a3GORzw0Mr2LCn\ngq89/iZn3PYse5OEXk19I6XlNeoCFUlgroM5Xelk2rRpbsWKFX1dDekBv39lK9/6v9W8c9usFiuh\nvBvdt3QTh2sb+J/FxS32E0zmhOEFHKiqT7rFEURHfs6ZPIqXNu5j7qyTuOCEIj7zu+UsXlfKKaMK\n+ft/vBeI7qf40d+8yOVnjOHqs8e3e8/qukayItZqRZ7usn1/FQ1Njgmh1XREusLMVjrnOpxLldK/\naDObaWbrzazYzOYmOW9mdmdw/k0zm9rRtWY22MwWmtmG4M/WE5fEG1fPOIYtt1/6rg87iLZwv/D+\nE1jxzfd3WPadPYfZH9odPtHew7Xc/8Jm3i4p59oHXuWPy7axeF0pEN1L8E/Lt7HzYDWPv7aDN3Yc\n4vtPrmXz3kp++8+N8W7kimDro/Kaei69cyknf/spPnnvMhJ/GS6tqGF78Byxqcm1WHQ8UUNjE0vW\nl7b6DIhuwnvhz55rsbN9Z9U3NvGrZzdwKFhgvaa+7boA3P/CZh5NcRHyjtz/wmaO//qC+N9fd9hx\noKrFFlTSMzps4ZlZBHgH+ACwA1gOXOmcWxsqMxv4PDAbOAv4lXPurPauNbOfAPudc7cHQTjIOffV\n9uqiFp6827y0cS+fvHdZj97jqhnjeHnjPjYm2cz3k2eN44/LokHwy3+dzBf+1LwSzL9OG4vD8eVL\nTuLZt/fwtcffwgweu+kc5j23kaUb9vLGdz7InvIabn30db5x6SSOHZpPfWNTfL/B+66ZxnkTh1JW\nURtfOGH83L/H7/HIv82gtKKG904sIiti1NQ3UdQ/urDC0g1lrNlVzqWnjWTEgFw2lVXy68UbeM+Y\nAfxowToAJg4r4Nv/Momr73+Vn3zsPQwrzOEPr2zlt1dPI5JhLHp7D5NGFXL2jxcD0d0pnHMpTe3Z\ntq+KjXsP8/q2g1w5fSwjB+RR39jExG/8A4D//fdzmDJuEDX1jS2+X2ds2VvJ2MH9OO7rCzh2aD6L\n/+t97Zb/0/JtNDbBR6eObnMQWFVdA3lZkfh3PFhVR2VdI/f8cyNfm31ym9c1NTkyMoxDVfVYBvTP\nyYx/hnOOp9fsoah/NoPzc9ptnZccqmZY/1wiGcbr2w7wYvFebrkotQXgj1SqLbxUAu9s4LvOuUuC\n918DcM79OFTmt8BzzrlHgvfrgfcB49u6NlbGOVdiZiOD65OvCRVQ4Mm7zaGqer70lze49eKJLNu8\nj588vb7VXn1h5x4/hBGFeTz22g7u/tRUFq0r5a8rd3De8UN5obj17vJH4suXnMhPn17fccEUnD5m\nAAer69m6r4rrzh3Pqu0HeX1b+1stnTKqkFNGFfLnFTvix8YOzmP7/uqU73vt2ceQn5PJb57b2OJ4\nbLf6GccO5mBVPVPGDWLGsYN5Z08Fh2saOHlkIb95bmPSXS1mnjKCmoZGnltfFj9222WncvdzG9l5\nsJpTRhVy7vFDyY5ksHlvJfWNTVx99jG8XVJOdV0T+TkRdh6sJjcrwo4D1eRmZvCXlTta3OPU0YWs\nK6ngkmDz5QOV9YwYkMOh6nrKqxv4nyXF8bJDC7L59DnjmTi8P5v3VrLrYDUvbNjLpr2VnH9CEeMG\n5zFyQF6r/y3/4+KJHD+sgOLSw5RX17Ox7DDLNu+nMDeLG86fwF1LNnKoup7jhxVw5vjBXHBCESu2\n7Oe+F5p3AfnIlNGMH5LP5r2HaXRwzOB+lByqYcn6UvZX1nHyyEI+fsYYvv9ktF00vDCH08cMZOap\nIyjIyWR/ZR1Li/dy+dQxXHhS1xfS6M7AuxyY6Zz7bPD+auAs59wtoTJPArc7514I3i8Cvko08JJe\na2YHnXMDg+MGHIi9b4sCT97tlqwr5brfLec/Lp7Ip88Zz/f+toYnVu3iyuljue7cCYwb3I9IhnGg\nsi6+fVRdQxPZmRn8deUO/usvb3BsUT6fO/9YvvrYW2RFjPpGx9CCbE4bPYAlof9YxwwtyOa4ogKW\nbd7PmEF5vPDVi/i3h1awcG3qm/iGF84GuOXC4xlWmMP3/7YWMxiQl510gA1E1zXdeTD1MOtr08cP\npqGpidc6CO7OysuKUN1B12x3yrDoLwDlNUfetRyWmWEdPpNO9OVLTuTmC4/v8r1TDby0mOXrnHNm\nlvRvysxuAG4AGDduXK/WS6S3XXjSMF6ce1F8cetfXTGFX10xpVW58F6JseeeH50ymrOPGxK/9qNT\nx9DY5HhnTwWTRhbigP2VdVTXNcZ3q6hvjHYh1jc61u+uYNyQaLfcvddM43BtA3srajGDcYP7YWbs\nr6xjQF4WZRW1FOZlsvNAtPvKMuBAZR2VtY1kRoyJwwowMy46aRhmxvD+OawtKWfisP40Okd2JIPM\nDKOkvIYRhbnsLq8hPztCTmaEDaUVZGdmEDGjMC+LQ9X1jBmUR1lFLVmRDPaU1zBhaD67y2swjEH9\nsqiub+RQdT11DU3k52QyrH9O8JmZ7KusY+zgPCpqGhg5IJfK2kZ2Haxm4vACDtc0sLu8huGFuVQF\nUz0mjSrkcE0Dg/Kz2VRWyZCCbOoamjCD8uoGThheQG1DExU1DfHuwnGD+9HQ1MT+yjoiZmRnZuAc\n8c/Oz4lQXh0NlqyIkZcdobHJMbx/Lu+UVpCfncmQgmzKKmrJMGN4YS6rdx2iqCCHfZV1TBiST5Nz\nlNfUc8yQfMoqasnMMMoO11Jb38TwwhzKa+oxM4b1z2FjWSUjCnPZU17D2MH94s8bG5scu8trKMjJ\nZOSAXPrnZuGco7j0MMMKc9l3uJaRA/LIy45QWdvA5r2V1NQ3kpFhDMnPZnhhLjsOVAFGv+wI9Y1N\nlFc3UNQ/h2H9c9hfVcfhmuj76vpGtu+vIj8nk4KcTCprG6ipb6KhqQkz44ThBSnv8dld1KUpIiJH\nte4cpbkcmGhmE8wsG7gCmJ9QZj5wTTBacwZwyDlX0sG184Frg9fXAk+kUBcREZEj0mGXpnOuwcxu\nAZ4GIsADzrk1ZnZjcH4esIDoCM1ioAq4rr1rg4++HfizmV0PbAU+0a3fTEREJEQTz0VE5KjWrRPP\nRUREjnYKPBER8YICT0REvKDAExERLyjwRETECwo8ERHxggJPRES8oMATEREvKPBERMQLCjwREfGC\nAk9ERLygwBMRES8cVYtHm1kZ0Z0VumoosLcbPqe3HE31PZrqCqpvT1N9e9bRVN+erOsxzrmijgod\nVYHXXcxsRSora6eLo6m+R1NdQfXtaapvzzqa6psOdVWXpoiIeEGBJyIiXvA18O7p6wp00tFU36Op\nrqD69jTVt2cdTfXt87p6+QxPRET842sLT0REPONV4JnZTDNbb2bFZja3r+sDYGYPmFmpma0OHRts\nZgvNbEPw56DQua8F9V9vZpf0QX3HmtkSM1trZmvM7NZ0rbOZ5ZrZq2b2RlDX76VrXRPqHTGz183s\nyXSvr5ltMbO3zGyVma04Cuo70Mz+ambrzOxtMzs7XetrZicGf6+xn3Iz+0Ia1/c/g/+frTazR4L/\n/6VXXZ1zXvwAEWAjcCyQDbwBTEqDep0PTAVWh479BJgbvJ4L/HfwelJQ7xxgQvB9Ir1c35HA1OB1\nf+CdoF5pV2fAgILgdRawDJiRjnVNqPcXgT8CTx4F/x62AEMTjqVzfR8EPhu8zgYGpnN9Q/WOALuB\nY9KxvsBoYDOQF7z/M/DpdKurTy286UCxc26Tc64OeBSY08d1wjn3PLA/4fAcov/HJPjzstDxR51z\ntc65zUAx0e/Va5xzJc6514LXFcDbRP+xp12dXdTh4G1W8OPSsa4xZjYGuBS4L3Q4bevbhrSsr5kN\nIPoL5v0Azrk659zBdK1vgouBjc65raRvfTOBPDPLBPoBu9Ktrj4F3mhge+j9juBYOhrunCsJXu8G\nhgev0+o7mNl4YArRllNa1jnoHlwFlAILnXNpW9fAL4GvAE2hY+lcXwc8a2YrzeyG4Fi61ncCUAb8\nv6DL+D4zyyd96xt2BfBI8Drt6uuc2wn8DNgGlACHnHPPpFtdfQq8o5KLtv/TbiitmRUAjwFfcM6V\nh8+lU52dc43OucnAGGC6mZ2acD5t6mpmHwJKnXMr2yqTTvUNnBf8/c4Cbjaz88Mn06y+mUQfH9zt\nnJsCVBLtZotLs/oCYGbZwIeBvySeS5f6Bs/m5hD9pWIUkG9mV4XLpENdfQq8ncDY0PsxwbF0tMfM\nRgIEf5YGx9PiO5hZFtGwe9g593hwOK3rHHRdLQFmkr51PRf4sJltIdrlfpGZ/YH0rW/sN3ucc6XA\n/xLtlkrX+u4AdgStfIC/Eg3AdK1vzCzgNefcnuB9Otb3/cBm51yZc64eeBw4J93q6lPgLQcmmtmE\n4DemK4D5fVyntswHrg1eXws8ETp+hZnlmNkEYCLwam9WzMyM6DOQt51zPw+dSrs6m1mRmQ0MXucB\nHwDWpWNdAZxzX3POjXHOjSf673Oxc+6qdK2vmeWbWf/Ya+CDwOp0ra9zbjew3cxODA5dDKxN1/qG\nXElzd2asXulW323ADDPrF/w34mKiz/fTq649PSomnX6A2URHFW4EvtHX9Qnq9AjRPu96or+BXg8M\nARYBG4BngcGh8t8I6r8emNUH9T2PaLfEm8Cq4Gd2OtYZeA/welDX1cC3g+NpV9ckdX8fzaM007K+\nREc8vxH8rIn9fypd6xvcfzKwIvg38X/AoDSvbz6wDxgQOpaW9QW+R/QXytXA74mOwEyrumqlFRER\n8YJPXZoiIuIxBZ6IiHhBgSciIl5Q4ImIiBcUeCIi4gUFnoiIeEGBJyIiXlDgiYiIF/4/wE3GNXC4\nMqEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26c712e7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # train with all train data to get feature_importances2_\n",
    "# #rf = RandomForestClassifier(n_jobs=-1,n_estimators=500,oob_score=True,max_features=0.25, random_state=0)\n",
    "# rf.fit(train, y)\n",
    "importances2 = rf.feature_importances_\n",
    "print(sum((importances2)>0.00001))\n",
    "print(sum((importances2)>0.00005))\n",
    "print(sum((importances2)>0.0001))\n",
    "print(sum((importances2)>0.0005))\n",
    "print(sum((importances2)>0.001))\n",
    "\n",
    "plt.plot(range(len(importances2)),importances2)\n",
    "plt.rcParams['figure.figsize'] = (7.0, 7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.55921479e-06,   4.28724050e-05,   0.00000000e+00,\n",
       "         9.23500678e-06,   0.00000000e+00,   4.25459025e-06,\n",
       "         1.10256223e-05,   1.79112381e-05,   6.89612637e-05,\n",
       "         1.60811279e-05,   3.00416401e-03,   4.29520560e-03,\n",
       "         5.50334685e-03,   4.90620290e-03,   5.18112838e-03,\n",
       "         5.63412383e-03,   5.65627635e-03,   7.72079052e-03,\n",
       "         4.81979696e-03,   5.06760333e-03])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances2[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, y)\n",
    "dtest = xgb.DMatrix(test)\n",
    "\n",
    "# # # reproducibility\n",
    "# seed = 342\n",
    "# np.random.seed(seed)\n",
    "import csv\n",
    "best_score=2\n",
    "\n",
    "denom = 0\n",
    "fold = 100\n",
    "for i in np.array(range(fold)):\n",
    "    np.random.seed( i) \n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 9,\n",
    "        'seed': np.random.randint(1,10000),#i,\n",
    "        'silent': True#,\n",
    "    }\n",
    "    params['nthread'] = -1#28#\n",
    "    params['min_child_weight'] = np.random.randint(2,8)#np.random.randint(2,10)\n",
    "    params['eta'] = np.random.uniform(0.015,0.04)\n",
    "    params['max_depth'] = np.random.randint(4,13)#np.random.randint(8,15)#\n",
    "#     params['subsample'] = np.random.uniform(0.8,1)\n",
    "#     params['colsample_bytree'] = np.random.uniform(0.5,1)\n",
    "    \n",
    "    score = xgb.cv(params, dtrain, 1500, nfold=5, verbose_eval=500, early_stopping_rounds=100)\n",
    "    score1=score.iloc[-1,0]\n",
    "    print(score1)\n",
    "    print(i)\n",
    "    print(params)\n",
    "    \n",
    "    if score1 < best_score:\n",
    "        np.save('best_params_fold_'  + str(i) + '.npy', params) \n",
    "        best_score=score1\n",
    "        best_params=params\n",
    "        best_nround=score.iloc[:,0].idxmin()\n",
    "        #min(score.iloc[:,0])\n",
    "\n",
    "watchlist= [(dtrain, 'train')]\n",
    "model = xgb.train(best_params, dtrain, best_nround,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "preds = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "submission = pd.DataFrame(preds, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission['ID'] = pid\n",
    "submission.to_csv('submission_xgb_cv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "56eb3035-949a-4129-a374-fcaff5142b90",
    "_execution_state": "idle",
    "_uuid": "0003d9e63a4d80882fcd8e015cf764332dc29eff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7.0, 7.0)\n",
    "xgb.plot_importance(booster=model); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
